{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages\n",
    "import numpy as np\n",
    "import cv2 \n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "from math import *\n",
    "import tifffile\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.optimize import curve_fit\n",
    "import string\n",
    "from pylab import *\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot formatting \n",
    "matplotlib.rcParams['mathtext.fontset']='cm'\n",
    "matplotlib.rcParams['font.family']='STIXGeneral'\n",
    "plt.rcParams['legend.fontsize']=15\n",
    "plt.rcParams.update({'font.size':15}) \n",
    "plt.rcParams['axes.axisbelow']=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Completeness Magnitude and best fit a (exponent stability)\n",
    "\n",
    "from: https://github.com/sachalapins/bvalues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Frequency-magnitude distribution function (Mignan & Woessner article) ######\n",
    "# mag: catalogue of magnitudes\n",
    "# mbin: magnitude bin size\n",
    "def fmd(mag, mbin):\n",
    "    minmag = math.floor(min(mag/mbin)) * mbin # Lowest magnitude bin\n",
    "    maxmag = math.ceil(max(mag/mbin)) * mbin # Highest magnitude bin\n",
    "    mi = np.arange(minmag, maxmag + mbin, mbin) # Sequence of magnitude bins\n",
    "    nbm = len(mi) # No. of magnitude bins\n",
    "    cumnbmag = np.zeros(nbm) # Pre-allocate array for cumulative no. of events in mag bin and higher\n",
    "\n",
    "    # Get cumulative no. of events in mag bin and higher\n",
    "    for i in range(nbm):\n",
    "        cumnbmag[i] = np.where(mag > mi[i] - mbin/2)[0].shape[0]\n",
    "        \n",
    "    # Get no. of events in each mag bin:\n",
    "    nbmag = abs(np.diff(np.append(cumnbmag, 0)))\n",
    "    \n",
    "    return mi, nbmag, cumnbmag # Return magnitude bins, no. of events in bin, and cumulative no. of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Function to get completeness magnitude with MAXC method ######\n",
    "def get_maxc(mag, mbin):\n",
    "    this_fmd = fmd(mag, mbin) # FMD\n",
    "    maxc = this_fmd[0][np.argmax(this_fmd[1])] # Mag bin with highest no. of events\n",
    "    return round(maxc, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Function to estimate b-value using maximum likelihood method (Aki, 1965), original Aki error estimate (Aki, 1965), and Shi & Bolt (1982) improved uncertainty estimate: \n",
    "# mag: catalogue of magnitudes\n",
    "# mbin: magnitude bin size\n",
    "# mc: completeness magnitude\n",
    "def b_est(mag, mbin, mc):\n",
    "    \n",
    "    mag_above_mc = mag[np.where(mag > round(mc,1)-mbin/2)[0]].values # Magnitudes for events larger than cut-off magnitude mc\n",
    "    n = mag_above_mc.shape[0] # No of. events larger than cut-off magnitude mc\n",
    "    if n < 2:\n",
    "        a = np.nan\n",
    "        b = np.nan\n",
    "        aki_unc = np.nan\n",
    "        shibolt_unc = np.nan\n",
    "    else:\n",
    "        mbar = np.mean(mag_above_mc) # Mean magnitude for events larger than cut-off magnitude mc\n",
    "        b = math.log10(math.exp(1)) / (mbar - (mc - mbin/2)) # b-value from Eq 3\n",
    "        a = math.log10(n) + b * mc # 'a-value' for Eq 2\n",
    "        aki_unc = b / math.sqrt(n) # Uncertainty estimate from Eq 4\n",
    "        shibolt_unc = 2.3 * b**2 * math.sqrt(sum((mag_above_mc - mbar)**2) / (n * (n-1))) # Uncertainty estimate from Eq 5\n",
    "        \n",
    "\n",
    "    return a, b, aki_unc, shibolt_unc # Return b-value and estimates of uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Method of b-Value Stability ######\n",
    "def get_mbs(mag, mbin, dM = 0.4, min_mc = -3):\n",
    "\n",
    "    this_fmd = fmd(mag, mbin) # FMD\n",
    "    this_maxc = get_maxc(mag, mbin) # Needed further down\n",
    "\n",
    "    # Zeros to accommodate synthetic GR distributions for each magnitude bin\n",
    "    a = np.zeros(this_fmd[0].shape[0]) # Pre-allocate array to accommodate a values from Eq 2\n",
    "    b = np.zeros(this_fmd[0].shape[0]) # Pre-allocate array to accommodate b values from Eq 2 & 3\n",
    "    b_avg = np.zeros(this_fmd[0].shape[0]) # Pre-allocate array to accommodate average b values from Eq 7\n",
    "    shibolt_unc = np.zeros(this_fmd[0].shape[0]) # Pre-allocate array to accommodate uncertainty values from Eq 5\n",
    "\n",
    "    # Loop through each magnitude bin, using it as cut-off magnitude\n",
    "    for i in range(this_fmd[0].shape[0]):\n",
    "        mi = round(this_fmd[0][i], 1) # Cut-off magnitude\n",
    "        \n",
    "        # make the correction for the fdm: ### new ###\n",
    "        #beta = 2.3026*b[i] # in natural log\n",
    "        #alpha = 2.3026*a[i] # in natural log\n",
    "        #exp_a_0 = (1-math.exp(-beta*mbin)) * (r*math.exp(beta*(Mmin + 0.5*mbin))) / (1 - math.exp(-beta(Mmax - Mmin)))\n",
    "        #fdm_corrected = exp_a_0 / math.exp(beta*mi)\n",
    "    \n",
    "        if this_fmd[2][i] > 1:\n",
    "      \n",
    "            a[i], b[i], tmp1, shibolt_unc[i] = b_est(mag, mbin, mi) # a and b-values for this cut-off magnitude\n",
    "        else:\n",
    "            a[i] = np.nan\n",
    "            b[i] = np.nan\n",
    "            shibolt_unc[i] = np.nan\n",
    "\n",
    "    # Loop through again, calculating rolling average b-value over following dM magnitude units\n",
    "    no_bins = round(dM/mbin)\n",
    "    check_bval_stability = []\n",
    "    for i in range(this_fmd[0].shape[0]):\n",
    "        if i >= this_fmd[0].shape[0] - (no_bins + 1):\n",
    "            b_avg[i] = np.nan\n",
    "            next\n",
    "        if any(np.isnan(b[i:(i+no_bins+1)])):\n",
    "            b_avg[i] = np.nan\n",
    "            check_bval_stability.append(False)\n",
    "        else:\n",
    "            b_avg[i] = np.mean(b[i:(i+no_bins+1)])\n",
    "            check_bval_stability.append(abs(b_avg[i] - b[i]) <= shibolt_unc[i])\n",
    "\n",
    "    if any(check_bval_stability):\n",
    "        bval_stable_points = this_fmd[0][np.array(check_bval_stability)]\n",
    "        mc = round(min(bval_stable_points[np.where(bval_stable_points > min_mc)[0]]), 1) # Completeness mag is first mag bin that satisfies Eq 7\n",
    "    else:\n",
    "        mc = this_maxc # If no stability point, use MAXC\n",
    "\n",
    "    return mc, this_fmd[0], b, b_avg, shibolt_unc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to be optimised with L2-norm in grid-search algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To find best fit (1) exponent of the power-law (correction of AKI's method) AND (2) bin-width of the crack length catalogue (in AKI's method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2func(m, Lambda, dm):\n",
    "    \n",
    "    ''' Function to minimise equation 17 of Geffers et al 2023 (https://doi.org/10.1093/gji/ggac436), \n",
    "        to find optimum parameters Lambda and dm:\n",
    "        Lambda = exponent of the power-law, correction of AKI's method\n",
    "        dm = bin-width of the crack length catalogue, used in AKI's method\n",
    "        \n",
    "        Returns the completeness magnitude (mc) calculated by the MBS method \n",
    "        and the output of eq. 17 of Geffers et al 2023.\n",
    "    '''\n",
    "    # maximum crack length\n",
    "    omega = np.max(m) \n",
    "    \n",
    "    # window length where MBS calculates b-vlaue (assumed to be 5xbin_width)\n",
    "    M_range = 5*dm\n",
    "    \n",
    "    # apply MBS method \n",
    "    mc, bins, b_AKI, b_avg, shibolt_unc = get_mbs(m, dm, M_range, min_mc = -5)\n",
    "    \n",
    "    # calculate b-value from MBS mc output\n",
    "    cat_a, cat_b, cat_aki_unc, cat_shibolt_unc = b_est(mag = m, mbin = dm, mc = mc)\n",
    "    \n",
    "    # convert b-value to Lambda (i.e. from base 10 to base e)\n",
    "    Lambda_AKI = cat_b/np.log10(np.exp(1))\n",
    "    \n",
    "    # equation 17 in Geffers et al, 2023 to be minimised\n",
    "    opt = (1/Lambda)*(1-(np.exp(Lambda*dm)-1)/(np.exp(Lambda*(omega - mc))-1)) - (1/Lambda_AKI)\n",
    "    \n",
    "    \n",
    "    return opt**2, mc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-search algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Residual_Thresholding_Fiji_output/whole_image/35-nt_s2.csv' # path to csv file with crack length data\n",
    "df_raw = pd.read_csv(path, delimiter=',') \n",
    "x = np.log(df_raw['Major']*0.00791*1000) #convert to microns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Grid search to minimise EQ 17 in Geffers et al. (2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lambda values\n",
    "Lambda2search = np.arange(1.2/np.log10(np.exp(1)), 2.5/np.log10(np.exp(1)) + 0.1, 0.1)\n",
    "#dm values\n",
    "dm2search = np.arange(0.02, 0.25 + 0.005, 0.005)\n",
    "#2D space of Lambda and dm\n",
    "L2 = np.ones([len(dm2search),len(Lambda2search)]) #for output of opt\n",
    "mcL2 = np.ones([len(dm2search),len(Lambda2search)]) #for mc\n",
    "\n",
    "for dm_i, Dm in enumerate(dm2search):\n",
    "    for L_i, L in enumerate(Lambda2search):\n",
    "        L2_i, mcL2_i = L2func(x, L, Dm) #call Function and obtain opt output and mc\n",
    "        L2[dm_i,L_i] = L2_i #assign opt output to grid-search grid\n",
    "        mcL2[dm_i,L_i] = mcL2_i #assign mc output to mcL2 grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Find the minimum in the grid and get the corresponding parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum in L2 eq\n",
    "minL2 = [np.where(L2==np.min(L2))[0][0], np.where(L2==np.min(L2))[1][0]]\n",
    "# dm that corresponds to that min in L2\n",
    "optdm = dm2search[minL2[0]]#dm2search[np.where(L2==np.min(L2))[0][0]]#dm2search[20]#\n",
    "# Lambda that corresponds to that min in L2\n",
    "optLambda = Lambda2search[minL2[1]]\n",
    "# mc that corresponds to that min in L2\n",
    "optMc = mcL2[minL2[0], minL2[1]] \n",
    "# b-value in base 10\n",
    "opt_b = np.log10(np.exp(1))*optLambda\n",
    "# mc in base 10\n",
    "log10Lc = np.log10(np.exp(1))*optMc\n",
    "optdm,  optLambda "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###FIGURE CONF\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(19,7))\n",
    "bottom, top = 0, 0.8\n",
    "left, right = 0, 0.9\n",
    "fig.subplots_adjust(top = top, bottom = bottom, left = left, right = right, hspace = 0.3, wspace = 0.3)\n",
    "\n",
    "\n",
    "###########################################################\n",
    "#          LEFT         #\n",
    "# gridsearch output\n",
    "im = ax[0].imshow(L2, vmin=0, vmax=0.001, origin=\"lower\", \n",
    "           extent=(Lambda2search[0]*np.log10(np.exp(1)),Lambda2search[-1]*np.log10(np.exp(1)),\n",
    "                   dm2search[0]*np.log10(np.exp(1)),dm2search[-1]*np.log10(np.exp(1))), \n",
    "           aspect=\"auto\")\n",
    "# absolute minimum \n",
    "ax[0].scatter(Lambda2search[np.where(L2==np.min(L2))[1][0]]*np.log10(np.exp(1)),\n",
    "             dm2search[np.where(L2==np.min(L2))[0][0]]*np.log10(np.exp(1)),c=\"red\")\n",
    "#ax[0].scatter(Lambda2search[12]*np.log10(np.exp(1)),dm2search[20]*np.log10(np.exp(1)),c=\"red\")\n",
    "# colorbar\n",
    "fmt = matplotlib.ticker.ScalarFormatter(useMathText=True)\n",
    "fmt.set_powerlimits((0, 0))\n",
    "fig.colorbar(im, label=\"Objective [L2]\", ax=ax[0],format=fmt)\n",
    "ax[0].set_xlabel(r\"a\") ; ax[0].set_ylabel(r\"$dm$\")\n",
    "\n",
    "\n",
    "\n",
    "###########################################################\n",
    "#          RIGHT         #\n",
    "## calling functions\n",
    "\n",
    "cat_mi, cat_nbmag, cat_cumnbmag = fmd(mag = x, mbin = optdm)\n",
    "cat_mbs = get_mbs(mag = x, mbin = optdm, dM = optdm*5) # MBS completeness magnitude\n",
    "cat_mc = cat_mbs[0] # GFT completeness magnitude\n",
    "cat_a, cat_b, cat_aki_unc, cat_shibolt_unc = b_est(mag = x, mbin = optdm, mc = cat_mc)\n",
    "\n",
    "## plotting results\n",
    "ax[1].scatter([], [], c='red', label = r'Min$_{glob}$(L2)')\n",
    "ax[1].axvline(log10Lc , color = 'black' , ls = '--' , label = r'MBS $l_c$')\n",
    "ax[1].scatter(cat_mi/np.log(10), cat_cumnbmag, marker = 's', color = 'black', alpha = 0.6, edgecolor = 'black'\n",
    "          , label = 'Cumulative no. of Cracks')\n",
    "ax[1].scatter(cat_mi/np.log(10), cat_nbmag, marker = 'o', color = 'black', alpha = 0.6, edgecolor = 'black'       , label = 'No. of Cracks')\n",
    "ax[1].plot(cat_mi/np.log(10), (10**(cat_a-0.65 - (opt_b * cat_mi))), color = 'dodgerblue', label = r'$\\log_{n}{(F)}= c - al$')\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].grid()\n",
    "ax[1].set_xlabel(r'log$_{10}\\left( l \\right)$ ($\\mu$m)')\n",
    "ax[1].set_ylabel('Frequency')\n",
    "ax[1].text(x=log10Lc+0.04, y=3e4, s=r'$l_c$ = ' + str(round(10**(log10Lc), 1))+r'$\\mu$m')\n",
    "ax[1].text(x=log10Lc+0.04, y=1e4, s=r'$a$ = ' + str(round(opt_b, 1)) + \" $\\pm$ \" + str(round(cat_shibolt_unc, 1)))\n",
    "ax[1].set_xlim(1, 3)\n",
    "ax[1].set_ylim(0.9, 10**5)\n",
    "ax[1].legend(loc=\"lower left\", bbox_to_anchor = (-1.25, -0.365), ncol=5, columnspacing = 0.7, handletextpad = 0.05)\n",
    "#### Label Subplots\n",
    "for n, a in enumerate(ax.flat):\n",
    "    a.text(-0.15, 0.98, string.ascii_lowercase[n]+\")\", transform = a.transAxes, size=22, weight = 'bold')\n",
    "print(opt_b, cat_b)\n",
    "fig.savefig('PAPER FIGURES/GridSearch_Sk35.png', bbox_inches='tight', dpi= 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing all images of both methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the following cells is in the csv files: Evolution_SK_all.csv, Evolution_RT_all.csv. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Residual Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "bval_GT = []\n",
    "Mc_GT = []\n",
    "\n",
    "Lambda2search = np.arange(1.2/np.log10(np.exp(1)), 2.5/np.log10(np.exp(1)) + 0.1, 0.1)\n",
    "#dm values\n",
    "dm2search = np.arange(0.02, 0.25 + 0.005, 0.005)\n",
    "\n",
    "for ff in range(0,36,2):\n",
    "    #DATA\n",
    "    df_raw = pd.read_csv('Residual_Thresholding_Fiji_output/whole_image/'+str(ff)+'-nt_s2.csv', delimiter=',') #import data\n",
    "    x = np.log(df_raw['Major']*0.00791*1000) #convert to microns\n",
    "    \n",
    "    #OPTIMISATION OF LAMBDA AND DM\n",
    "    #2D space of Lambda and dm\n",
    "    L2 = np.ones([len(dm2search),len(Lambda2search)]) #for output of opt\n",
    "    mcL2 = np.ones([len(dm2search),len(Lambda2search)]) #for mc\n",
    "\n",
    "    for dm_i, Dm in enumerate(dm2search):\n",
    "        for L_i, L in enumerate(Lambda2search):\n",
    "            L2_i, mcL2_i = L2func(x, L, Dm) #call Function and obtain opt output and mc\n",
    "            L2[dm_i,L_i] = L2_i #assign opt output to grid-search grid\n",
    "            mcL2[dm_i,L_i] = mcL2_i #assign mc output to mcL2 grid\n",
    "\n",
    "    minL2 = [np.where(L2==np.min(L2))[0][0], np.where(L2==np.min(L2))[1][0]]\n",
    "    # dm that corresponds to that min in L2\n",
    "    optdm = dm2search[minL2[0]]#dm2search[np.where(L2==np.min(L2))[0][0]]#dm2search[20]#\n",
    "    # Lambda that corresponds to that min in L2\n",
    "    optLambda = Lambda2search[minL2[1]]#\n",
    "    # mc that corresponds to that min in L2\n",
    "    optMc = mcL2[minL2[0], minL2[1]] \n",
    "    # b-value in base 10\n",
    "    opt_b = np.log10(np.exp(1))*optLambda\n",
    "    # mc in base 10\n",
    "    log10Lc = np.log10(np.exp(1))*optMc\n",
    "    print(ff)\n",
    "    #APPEND VALUES \n",
    "    bval_GT.append(opt_b)\n",
    "    Mc_GT.append(log10Lc)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "a = np.array(bval_GT)\n",
    "b = np.array(Mc_GT)\n",
    "c = np.arange(0,36,2)\n",
    "\n",
    "df = pd.DataFrame({\"Image\":c, \"b_val\" : a, \"Mc\" : b})\n",
    "df.to_csv(\"Evolution_GT_all.csv\", index=False)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Skeletonisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "bval_SK = []\n",
    "Mc_SK = []\n",
    "\n",
    "Lambda2search = Lambda2search = np.arange(2.5/np.log10(np.exp(1)), 5.5/np.log10(np.exp(1)) + 0.3, 0.3)\n",
    "#dm values\n",
    "dm2search = np.arange(0.02, 0.25 + 0.005, 0.005)\n",
    "\n",
    "for ff in range(0,36,2):\n",
    "    #DATA\n",
    "    df_raw = pd.read_csv('Griff_new_all/FIJI_out_s1/whole/'+str(ff)+'-s1_lukeout.csv', delimiter=',') #import data\n",
    "\n",
    "    x = np.log(df_raw['Major']*0.00791*1000) #convert to microns\n",
    "    \n",
    "    #OPTIMISATION OF LAMBDA AND DM\n",
    "    #2D space of Lambda and dm\n",
    "    L2 = np.ones([len(dm2search),len(Lambda2search)]) #for output of opt\n",
    "    mcL2 = np.ones([len(dm2search),len(Lambda2search)]) #for mc\n",
    "\n",
    "    for dm_i, Dm in enumerate(dm2search):\n",
    "        for L_i, L in enumerate(Lambda2search):\n",
    "            L2_i, mcL2_i = L2func(x, L, Dm) #call Function and obtain opt output and mc\n",
    "            L2[dm_i,L_i] = L2_i #assign opt output to grid-search grid\n",
    "            mcL2[dm_i,L_i] = mcL2_i #assign mc output to mcL2 grid\n",
    "\n",
    "    minL2 = [np.where(L2==np.min(L2))[0][0], np.where(L2==np.min(L2))[1][0]]\n",
    "    # dm that corresponds to that min in L2\n",
    "    optdm = dm2search[minL2[0]]#dm2search[np.where(L2==np.min(L2))[0][0]]#dm2search[20]#\n",
    "    # Lambda that corresponds to that min in L2\n",
    "    optLambda = Lambda2search[minL2[1]]#\n",
    "    # mc that corresponds to that min in L2\n",
    "    optMc = mcL2[minL2[0], minL2[1]] \n",
    "    # b-value in base 10\n",
    "    opt_b = np.log10(np.exp(1))*optLambda\n",
    "    # mc in base 10\n",
    "    log10Lc = np.log10(np.exp(1))*optMc\n",
    "    print(ff)\n",
    "    #APPEND VALUES \n",
    "    bval_SK.append(opt_b)\n",
    "    Mc_SK.append(log10Lc)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "a1 = np.array(bval_SK)\n",
    "b1 = np.array(Mc_SK)\n",
    "c1 = np.arange(0,36,2)\n",
    "\n",
    "df1 = pd.DataFrame({\"Image\":c1, \"b_val\" : a1, \"Mc\" : b1})\n",
    "df1.to_csv(\"Evolution_SK_all.csv\", index=False)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the output of the previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_SK = pd.read_csv(\"Evolution_SK_all.csv\")\n",
    "E_GT = pd.read_csv(\"Evolution_GT_all.csv\")\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n",
    "bottom, top = 0, 0.8\n",
    "left, right = 0, 0.9\n",
    "fig.subplots_adjust(top = top, bottom = bottom, left = left, right = right, hspace = 0.3, wspace = 0.2)\n",
    "\n",
    "#evolution a value\n",
    "ax[0].plot(E_SK['Image'],E_SK['b_val'], c ='darkorange', label='SK', lw=3)\n",
    "ax[0].plot(E_GT['Image'],E_GT['b_val'], c ='dodgerblue', label='RT', lw=3)\n",
    "\n",
    "#evolution completeness length\n",
    "ax[1].plot(E_SK['Image'],10**E_SK['Mc'], c ='darkorange', lw=3)\n",
    "ax[1].plot(E_GT['Image'],10**E_GT['Mc'], c ='dodgerblue', lw=3)\n",
    "\n",
    "#peak stress\n",
    "ax[0].axvline(x = 18, label = 'Peak Stress', c = 'k', ls = '--', lw=2)\n",
    "ax[1].axvline(x = 18, c= 'k', ls = '--', lw=2)\n",
    "\n",
    "#average A values\n",
    "ax[0].hlines(y = E_SK['b_val'].iloc[0:10].mean(), xmin=0, xmax=18,colors ='darkorange', lw=2, ls='dotted' )\n",
    "ax[0].hlines(y = E_SK['b_val'].iloc[10:].mean(), xmin=18, xmax=34,colors ='darkorange', lw=2, ls='dotted' )\n",
    "ax[0].hlines(y = E_GT['b_val'].iloc[0:10].mean(), xmin=0, xmax=18,colors ='dodgerblue', lw=2, ls='dotted' )\n",
    "ax[0].hlines(y = E_GT['b_val'].iloc[10:].mean(), xmin=18, xmax=34,colors ='dodgerblue', lw=2, ls='dotted' , label = 'Mean')\n",
    "#average Mc values\n",
    "ax[1].hlines(y = 10**E_SK['Mc'].iloc[0:10].mean(), xmin=0, xmax=18,colors ='darkorange', lw=2, ls='dotted' )\n",
    "ax[1].hlines(y = 10**E_SK['Mc'].iloc[10:].mean(), xmin=18, xmax=34,colors ='darkorange', lw=2, ls='dotted' )\n",
    "ax[1].hlines(y = 10**E_GT['Mc'].iloc[0:10].mean(), xmin=0, xmax=18,colors ='dodgerblue', lw=2, ls='dotted' )\n",
    "ax[1].hlines(y = 10**(E_GT['Mc'].iloc[10:].mean()), xmin=18, xmax=34,colors ='dodgerblue', lw=2, ls='dotted' )\n",
    "\n",
    "#fill between\n",
    "#ax[0].fill_between(, y1, y2=0, where=None, interpolate=False, step=None, *, data=None, **kwargs)\n",
    "ax[0].fill_between(x = E_SK['Image'].iloc[0:10], y1 = E_SK['b_val'].iloc[0:10].mean()-E_SK['b_val'].iloc[0:10].std()\n",
    "                   ,y2 = E_SK['b_val'].iloc[0:10].mean()+E_SK['b_val'].iloc[0:10].std(),color ='darkorange',\n",
    "                  alpha = 0.1)\n",
    "ax[0].fill_between(x = E_SK['Image'].iloc[9:], y1 = E_SK['b_val'].iloc[10:].mean()-E_SK['b_val'].iloc[5:].std()\n",
    "                   ,y2 = E_SK['b_val'].iloc[10:].mean()+E_SK['b_val'].iloc[10:].std(),color ='darkorange',\n",
    "                  alpha = 0.1)\n",
    "ax[0].fill_between(x = E_GT['Image'].iloc[0:10], y1 = E_GT['b_val'].iloc[0:10].mean()-E_GT['b_val'].iloc[0:10].std()\n",
    "                   ,y2 = E_GT['b_val'].iloc[0:10].mean()+E_GT['b_val'].iloc[0:10].std(),color ='dodgerblue',\n",
    "                  alpha = 0.1 )\n",
    "ax[0].fill_between(x = E_GT['Image'].iloc[9:], y1 = E_GT['b_val'].iloc[10:].mean()-E_GT['b_val'].iloc[10:].std()\n",
    "                   ,y2 = E_GT['b_val'].iloc[10:].mean()+E_GT['b_val'].iloc[10:].std(),color ='dodgerblue',\n",
    "                  alpha = 0.1 , label = 'Std')\n",
    "\n",
    "\n",
    "\n",
    "ax[1].fill_between(x = E_SK['Image'].iloc[0:10], y1 = 10**(E_SK['Mc'].iloc[0:10].mean()-E_SK['Mc'].iloc[0:10].std())\n",
    "                   ,y2 = 10**(E_SK['Mc'].iloc[0:10].mean()+E_SK['Mc'].iloc[0:10].std()),color ='darkorange',\n",
    "                  alpha = 0.1)\n",
    "ax[1].fill_between(x = E_SK['Image'].iloc[9:], y1 = 10**(E_SK['Mc'].iloc[10:].mean()-E_SK['Mc'].iloc[10:].std())\n",
    "                   ,y2 = 10**(E_SK['Mc'].iloc[10:].mean()+E_SK['Mc'].iloc[10:].std()),color ='darkorange',\n",
    "                  alpha = 0.1)\n",
    "ax[1].fill_between(x = E_GT['Image'].iloc[0:10], y1 = 10**(E_GT['Mc'].iloc[0:10].mean()-E_GT['Mc'].iloc[0:10].std())\n",
    "                   ,y2 = 10**(E_GT['Mc'].iloc[0:10].mean()+E_GT['Mc'].iloc[0:10].std()),color ='dodgerblue',\n",
    "                  alpha = 0.1 )\n",
    "ax[1].fill_between(x = E_GT['Image'].iloc[9:], y1 = 10**(E_GT['Mc'].iloc[10:].mean()-E_GT['Mc'].iloc[10:].std())\n",
    "                   ,y2 = 10**(E_GT['Mc'].iloc[10:].mean()+E_GT['Mc'].iloc[10:].std()),color ='dodgerblue',\n",
    "                  alpha = 0.1 )\n",
    "\n",
    "\n",
    "#customising\n",
    "ax[0].set_xlabel('Image Number')\n",
    "ax[1].set_xlabel('Image Number')\n",
    "ax[0].set_ylabel(r'$a$')\n",
    "ax[1].set_ylabel(r'$l_{c}$ ($\\mu$m)')\n",
    "#ax[0].plot([], [], c = 'dodgerblue', alpha = 0.1, label = 'Std')\n",
    "\n",
    "ax[0].legend(loc=\"upper left\", bbox_to_anchor = (0.08, 1.25),ncol = 5)\n",
    "ax[0].grid()\n",
    "ax[1].grid()\n",
    "for n, a in enumerate(ax):\n",
    "    a.text(-0.099, 0.96, string.ascii_lowercase[n]+\")\", transform = a.transAxes, size=22, weight = 'bold')\n",
    "fig.savefig('PAPER FIGURES/evolution_lc_a.png', bbox_inches='tight', dpi= 200)        "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
