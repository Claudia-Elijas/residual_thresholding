{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Required packages\n",
    "import numpy as np\n",
    "import cv2 \n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "from math import *\n",
    "import tifffile\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.optimize import curve_fit\n",
    "import string\n",
    "from pylab import *\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Plot formatting \n",
    "matplotlib.rcParams['mathtext.fontset']='cm'\n",
    "matplotlib.rcParams['font.family']='STIXGeneral'\n",
    "plt.rcParams['legend.fontsize']=15\n",
    "plt.rcParams.update({'font.size':15}) \n",
    "plt.rcParams['axes.axisbelow']=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crack orientation rose diagram of filtered lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Shear Band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### USING STACK HISTOGRAMS ###\n",
    "########## Figure ##########\n",
    "fig, ax = plt.subplots(2,3, subplot_kw={'projection':'polar'}, figsize=(17,10))\n",
    "bottom, top = 0, 1\n",
    "left, right = 0, 1\n",
    "fig.subplots_adjust(top = top, bottom = bottom, left = left, right = right, hspace = 0.3, wspace = 0.081)\n",
    "## custom ##\n",
    "titles = [r'80$\\mu$m > $L$', r'40$\\mu$m < $L$ < 80$\\mu$m', \n",
    "          r'$L$ < 40$\\mu$m', r'80$\\mu$m > $L$', r'40$\\mu$m < $L$ < 80$\\mu$m', \n",
    "           r'$L$ < 40$\\mu$m']\n",
    "for n, a in enumerate(ax.flat):\n",
    "    #set title:\n",
    "    a.set_title(titles[n])\n",
    "    #set max length:\n",
    "    a.set_rmax(180)\n",
    "    #subplot label\n",
    "    a.text(-0.15, 1.122, string.ascii_lowercase[n]+\")\", transform = a.transAxes, size=22, weight = 'bold')\n",
    "## plot ##\n",
    "## top row of plots: global thresholding\n",
    "FL = [10000, 10, 5, 0]\n",
    "#### ERANGA BLUE\n",
    "for i in range(3):\n",
    "    stackedL1 = np.zeros(36)#np.zeros(89)\n",
    "    for f in range(37):\n",
    "        #read csv file\n",
    "        df1 = pd.read_csv('Residual_Thresholding_Fiji_output/shear_band/'+str(f)+'-nt_s2_roi.csv', delimiter=',')\n",
    "        #Filter length below 10 pixels\n",
    "        filt = df1[(df1['Major'] <= FL[i])&(df1['Major'] > FL[i+1])] #filter\n",
    "        #make histogram  \n",
    "        counts1, bins1 = np.histogram(filt['Angle'], bins=36)\n",
    "        \n",
    "        #stack bins   \n",
    "        stackedL1 += counts1\n",
    "        axis1 = bins1[:-1] \n",
    "    #print(len(stackedL1))\n",
    "    two_halves1 = np.concatenate([stackedL1, stackedL1]) #concatenate\n",
    "    ax[0,i].bar(np.deg2rad(np.linspace(0, 355, 72)), two_halves1, width=np.deg2rad(5),bottom=0.0,\n",
    "            alpha= 0.6, color='dodgerblue',edgecolor='k') #plot\n",
    "\n",
    "ax[0,0].set_rgrids(np.arange(0, 300, 100), angle=25)\n",
    "ax[0,1].set_rgrids(np.arange(0, 300, 100), angle=25)    \n",
    "ax[0,2].set_rgrids(np.arange(0, 1500, 500), angle=25)\n",
    "    \n",
    "#### GRIFF ORANGE\n",
    "for j in range(3):\n",
    "    stackedL1 = np.zeros(36)#np.zeros(89)\n",
    "    for f in range(37):\n",
    "        #read csv file\n",
    "        df1 = pd.read_csv('Skeletonisation_Fiji_output/shear_band/'+str(f)+'-s1_lukeout_roi.csv', delimiter=',')\n",
    "        #Filter length below 10 pixels\n",
    "        filt = df1[(df1['Major'] <= FL[j])&(df1['Major'] > FL[j+1])] #filter\n",
    "        #make histogram  \n",
    "        counts1, bins1 = np.histogram(filt['Angle'], bins=36)\n",
    "        \n",
    "        #stack bins   \n",
    "        stackedL1 += counts1\n",
    "        axis1 = bins1[:-1] \n",
    "\n",
    "    two_halves1 = np.concatenate([stackedL1, stackedL1]) #concatenate\n",
    "    ax[1,j].bar(np.deg2rad(np.linspace(0, 355, 72)), two_halves1, width=np.deg2rad(5),bottom=0.0,\n",
    "            alpha= 0.6, color='darkorange',edgecolor='k') #plot\n",
    "ax[1,0].set_rgrids(np.arange(0, 500, 100), angle=25)\n",
    "ax[1,1].set_rgrids(np.arange(0, 500, 100), angle=25)\n",
    "ax[1,2].set_rgrids(np.arange(0,  800, 200), angle=25)  \n",
    "ax_flat = ax.flat\n",
    "# Format radial labels in scientific notation\n",
    "import matplotlib.ticker as ticker\n",
    "def format_func(x, pos):\n",
    "        exponent = np.floor(np.log10(x)) if x != 0 else 0\n",
    "        coeff = x / 10**exponent\n",
    "        return r'${0} \\cdot 10^{{{1}}}$'.format(int(coeff), int(exponent)) if coeff != 1 else r'$10^{{{0}}}$'.format(int(exponent))\n",
    "\n",
    "for a in ax_flat:\n",
    "    a.yaxis.set_major_formatter(formatter)\n",
    "    a.tick_params(axis='y', labelsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Whole Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Figure ##########\n",
    "fig, ax = plt.subplots(2,3, subplot_kw={'projection':'polar'}, figsize=(17,10))\n",
    "bottom, top = 0, 1\n",
    "left, right = 0, 1\n",
    "fig.subplots_adjust(top = top, bottom = bottom, left = left, right = right, hspace = 0.3, wspace = 0.081)\n",
    "## custom ##\n",
    "titles = [r'80$\\mu$m > $L$', r'40$\\mu$m < $L$ < 80$\\mu$m', \n",
    "          r'$L$ < 40$\\mu$m', r'80$\\mu$m > $L$', r'40$\\mu$m < $L$ < 80$\\mu$m', \n",
    "           r'$L$ < 40$\\mu$m']\n",
    "for n, a in enumerate(ax.flat):\n",
    "    #set title:\n",
    "    a.set_title(titles[n])\n",
    "    #set max length:\n",
    "    a.set_rmax(180)\n",
    "    #subplot label\n",
    "    a.text(-0.15, 1.122, string.ascii_lowercase[n]+\")\", transform = a.transAxes, size=22, weight = 'bold')\n",
    "\n",
    "## top row of plots: global thresholding\n",
    "FL = [10000, 10, 5, 0]\n",
    "#### ERANGA BLUE\n",
    "for i in range(3):\n",
    "    stackedL1 = np.zeros(36)#np.zeros(89)\n",
    "    for f in range(37):\n",
    "        #read csv file\n",
    "        df1 = pd.read_csv('Residual_Thresholding_Fiji_output/whole_image/'+str(f)+'-nt_s2.csv', delimiter=',')\n",
    "        #Filter length below 10 pixels\n",
    "        filt = df1[(df1['Major'] <= FL[i])&(df1['Major'] > FL[i+1])] #filter\n",
    "        #make histogram  \n",
    "        counts1, bins1 = np.histogram(filt['Angle'], bins=36)\n",
    "        \n",
    "        #stack bins   \n",
    "        stackedL1 += counts1\n",
    "        axis1 = bins1[:-1] \n",
    "    #print(len(stackedL1))\n",
    "    two_halves1 = np.concatenate([stackedL1, stackedL1]) #concatenate\n",
    "    ax[0,i].bar(np.deg2rad(np.linspace(0, 355, 72)), two_halves1, width=np.deg2rad(5),bottom=0.0,\n",
    "            alpha= 0.6, color='dodgerblue',edgecolor='k') #plot\n",
    "    \n",
    "#### GRIFF ORANGE\n",
    "for j in range(3):\n",
    "    stackedL1 = np.zeros(36)#np.zeros(89)\n",
    "    for f in range(37):\n",
    "        #read csv file\n",
    "        df1 = pd.read_csv('Skeletonisation_Fiji_output/whole_image/'+str(n)+'-s1_lukeout.csv', delimiter=',')\n",
    "        #Filter length below 10 pixels\n",
    "        filt = df1[(df1['Major'] <= FL[j])&(df1['Major'] > FL[j+1])] #filter\n",
    "        #make histogram  \n",
    "        counts1, bins1 = np.histogram(filt['Angle'], bins=36)\n",
    "        \n",
    "        #stack bins   \n",
    "        stackedL1 += counts1\n",
    "        axis1 = bins1[:-1] \n",
    "\n",
    "    two_halves1 = np.concatenate([stackedL1, stackedL1]) #concatenate\n",
    "    ax[1,j].bar(np.deg2rad(np.linspace(0, 355, 72)), two_halves1, width=np.deg2rad(5),bottom=0.0,\n",
    "            alpha= 0.6, color='darkorange',edgecolor='k') #plot\n",
    "\n",
    "ax_flat = ax.flat\n",
    "# Format radial labels in scientific notation\n",
    "import matplotlib.ticker as ticker\n",
    "def format_func(x, pos):\n",
    "        exponent = np.floor(np.log10(x)) if x != 0 else 0\n",
    "        coeff = x / 10**exponent\n",
    "        return r'${0} \\cdot 10^{{{1}}}$'.format(int(coeff), int(exponent)) if coeff != 1 else r'$10^{{{0}}}$'.format(int(exponent))\n",
    "\n",
    "for a in ax_flat:\n",
    "    a.set_rgrids(np.arange(0, 5100, 1000), angle=25)\n",
    "    a.set_rgrids(np.arange(0, 500, 100), angle=25)\n",
    "    formatter = ticker.FuncFormatter(format_func)\n",
    "    a.yaxis.set_major_formatter(formatter)\n",
    "    a.tick_params(axis='y', labelsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting crack orientation distribution histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_orientations(path, nameR, nameW, f): \n",
    "    ### FINDING NORMALISING FACTOR ###\n",
    "    \n",
    "    #filtered normalising csv for roi\n",
    "    roi1 = pd.read_csv(path+'/roi/0'+nameR, delimiter=',') \n",
    "    roi1['Major adjusted']=roi1['Major']\n",
    "    roi1 = roi1[roi1['Major adjusted'] >= f]\n",
    "     \n",
    "    #filtered normalising csv for whole image\n",
    "    whole1 = pd.read_csv(path+'/whole/0'+nameW, delimiter=',')\n",
    "    whole1['Major adjusted']= whole1['Major']\n",
    "    whole1= whole1[whole1['Major adjusted'] >= f] \n",
    "    \n",
    "    #Normalising by frequency of first image\n",
    "    bins = np.arange(0, 180,2)\n",
    "    bin1, count1 = np.histogram(roi1['Angle'], bins=bins)\n",
    "    min_roi_luke = np.amin(np.array(bin1)[bin1 != np.amin(bin1)])  #NORMALISER ROI\n",
    "    bin2, count2 = np.histogram(whole1['Angle'], bins=bins)\n",
    "    min_whole_luke = np.amin(np.array(bin2)[bin2 != np.amin(bin2)]) #NORMALISER WHOLE IMAGE\n",
    "    bin3, count3 = np.abs(bin2-bin1), np.abs(count2-count1)\n",
    "    min_outside = np.amin(np.array(bin3)[bin3 != np.amin(bin3)]) #NORMALISER OUTSIDE ROI\n",
    "\n",
    "    ### PLOTTING ####\n",
    "    #fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(22,9))\n",
    "    bottom, top = 0, 1\n",
    "    left, right = 0, 0.9\n",
    "    fig.subplots_adjust(top = top, bottom = bottom, left = left, right = right, hspace = 0.3, wspace = 0.1)\n",
    "    ######################################################################################################################\n",
    "    select = list(range(0,37,1))#list(range(0,37,1)) #####################################################################\n",
    "    colors = plt.cm.viridis(np.linspace(0,1,37))\n",
    "    cmap = plt.get_cmap('viridis', 37)\n",
    "    stackedL1 = np.zeros(89)#np.zeros(89)\n",
    "    stackedL2 = np.zeros(89)\n",
    "    \n",
    "    for i in select:\n",
    "        df1 = pd.read_csv(path+'/shear_band/'+str(i)+nameR, delimiter=',')\n",
    "        df2 = pd.read_csv(path+'/whole_image/'+str(i)+nameW, delimiter=',')              \n",
    "        df1['Major adjusted']=df1['Major']\n",
    "        df2['Major adjusted']=df2['Major']\n",
    "        ##Filter length below 10 pixels\n",
    "        df1 = df1[df1['Major adjusted'] >= f]\n",
    "        df2 = df2[df2['Major adjusted'] >= f]\n",
    "        \n",
    "        bins1, counts1 = np.histogram(df1['Angle'], bins)\n",
    "        bins2, counts2 = np.histogram(df2['Angle'], bins)\n",
    "        #histograms for each image\n",
    "        ax[0,0].plot(counts1[:-1], bins1/min_roi_luke,'-',c=colors[i],  label=str(i))\n",
    "        ax[0,1].plot(counts2[:-1], bins2/min_whole_luke,'-',c=colors[i], label=str(i))  \n",
    "        ax[0,2].plot(counts2[:-1], np.abs(bins1 - bins2)/min_outside,'-',c=colors[i], label=str(i))  \n",
    "        \n",
    "        #stacking of the bins\n",
    "        stackedL1 += bins1\n",
    "        stackedL2 += bins2\n",
    "        axis1 = counts1[:-1]\n",
    "        axis2 = counts2[:-1] \n",
    "        \n",
    "    \n",
    "    #####COLOUR BAR\n",
    "    norm = mpl.colors.Normalize(vmin=0, vmax=36)#Normalizer\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)# creating ScalarMappable\n",
    "    sm.set_array([])\n",
    "    #create colorbar axes\n",
    "    cbar_ax = fig.add_axes([0.9, bottom, 0.05, top-bottom], aspect = 1)\n",
    "    fig.colorbar(sm, cax = cbar_ax, ticks = np.linspace(0,36,37), orientation='vertical')\n",
    "    for label in cbar_ax.yaxis.get_ticklabels()[::2]:\n",
    "        label.set_visible(False)\n",
    "    cbar_ax.set_ylabel('Image Number')\n",
    "\n",
    "    ###STACKED \n",
    "    ax[1,0].bar(axis1, stackedL1, width = 2,color='dodgerblue', edgecolor = 'black', alpha=0.8)\n",
    "    ax[1,1].bar(axis2, stackedL2,width = 2, color='dodgerblue', edgecolor = 'black', alpha=0.8)\n",
    "    ax[1,2].bar(axis2, np.abs(stackedL1-stackedL2),width = 2, color='dodgerblue', edgecolor = 'black', alpha=0.8)\n",
    "    \n",
    "   \n",
    "    ###FINDING MODE, MEAN and NetTheta OF STACKED HISTOGRAM\n",
    "    data = [stackedL1, stackedL2, np.abs(stackedL1-stackedL2)]\n",
    "    region = ['--ROI--', '--WHOLE--', '--OUTSIDE ROI--']\n",
    "    for m in range(3):\n",
    "        print(region[m])\n",
    "        \n",
    "        #SMOOTH TREND AND PLOT IT #################################\n",
    "        smooth_y = savgol_filter(data[m],51, 4) # window size , polynomial order \n",
    "        ax[1,m].plot(axis1, smooth_y, lw=3, c='darkorange',  label = 'Smoothed Distribution')\n",
    "        #find the argmax of the smoothed trend between above 45 degrees to avoid picking 0 angle\n",
    "        ims = (np.argmax(smooth_y[20:]) + 20 ) *2\n",
    "        print( 'IMS = '+str(ims))\n",
    "        #plot peak \n",
    "        ax[1,m].axvline(x = ims, lw=4, c='darkorange', ls='--', label = 'Smoothed Distribution Mode')\n",
    "        \n",
    "        #INVESTIGATE ASYMMETRY\n",
    "        mid = int(len(axis1)/2) # middle INDEX of the histogram range \n",
    "        #print(axis1[mid+1], axis1[0])\n",
    "        dif_sq = 0 # difference squared\n",
    "        for a in range(mid+1):\n",
    "            #print(a)\n",
    "            dif_sq = dif_sq +((data[m][a] - data[m][88 - a]))\n",
    "        MSD = dif_sq/mid # calculate the mean-sqare difference                \n",
    "      \n",
    "        ###CALCULATING THE MODE AND MEAN FOR EACH QUADRANT\n",
    "        sel = [0, mid, len(axis1), 0]\n",
    "        #print(int(len(axis1)/2))\n",
    "        means = []\n",
    "        modes = []\n",
    "        stds = []\n",
    "        for i in range(3):\n",
    "            #MODE\n",
    "            a = sel[i]\n",
    "            b = sel[i+1]\n",
    "            #print(i, a,b )\n",
    "            if i == 2:\n",
    "                #print('bbb')\n",
    "                a = 0\n",
    "                b = len(axis1)\n",
    "            #print(i, a,b )\n",
    "                \n",
    "            max_freq_bin = np.argmax(data[m][a:b])\n",
    "            \n",
    "            mode_bin_edges = (axis1[max_freq_bin], axis1[max_freq_bin + 1])\n",
    "            mode_value = np.mean(mode_bin_edges)\n",
    "            #print('Mode '+region[m]+' = '+str(mode_value))\n",
    "            if i ==1 :\n",
    "                mode_value = mode_value + (int(len(axis1)/2)+1)*2\n",
    "            #ax[1,m].axvline(mode_value,c='k', lw=4)\n",
    "            modes.append(mode_value)\n",
    "            ####MEAN WEIGHTED\n",
    "            bin_centers = 0.5*(counts1[1:]+counts1[:-1])\n",
    "            print(bin_centers)\n",
    "            #weighted_sum = np.sum(bin_centers[a:b] * data[m][a:b])\n",
    "            #total_sum = np.sum(data[m][a:b])\n",
    "            #mean = weighted_sum / total_sumn #weighted\n",
    "            mean =  np.mean(bin_centers) #non-weighted\n",
    "            means.append(mean)\n",
    "            ####STANDARD DEVIATION WEIGHTED\n",
    "            #std = np.sqrt(np.cov(bin_centers[a:b]-mean, fweights= data[m][a:b]))   \n",
    "            std = np.sqrt(np.cov(bin_centers[a:b]-mean))\n",
    "            stds.append(std)\n",
    "        \n",
    "        print('Means [synthetic, antithetic, whole] = '+str(means))\n",
    "        print('Stds [synthetic, antithetic, whole] = '+str(stds))\n",
    "        print('Modes [synthetic, antithetic, whole] = '+str(modes))\n",
    "        \n",
    "        \n",
    "        \n",
    "        #PLOT MODES AND MEAN for legend\n",
    "        ax[1,m].axvline(modes[2],c='k', ls = '--', lw=4, label = 'Mode')\n",
    "        ax[1,m].axvline(means[2],c='k', ls='-', lw=4, label = 'Mean')\n",
    "        \n",
    "   \n",
    "        ###CALCULATING THE NET THETA FOR BOTH QUADRANTS\n",
    "        #first quadrant (antithetic)\n",
    "        sinT_sum_1 = 0.0\n",
    "        cosT_sum_1 = 0.0\n",
    "       \n",
    "        #second quadrant (synthetic)\n",
    "        sinT_sum_2 = 0.0\n",
    "        cosT_sum_2 = 0.0\n",
    "       \n",
    "        for b in range(0, int(len(axis1)/2)):\n",
    "            #Angles\n",
    "            sinT_i = data[m][b]*np.sin(np.radians(axis1[b]))\n",
    "            sinT_sum_1 = sinT_sum_1 + sinT_i\n",
    "            \n",
    "            cosT_i = data[m][b]*np.cos(np.radians(axis1[b]))\n",
    "            cosT_sum_1 = cosT_sum_1 + cosT_i\n",
    "        \n",
    "        for c in range(int(len(axis1)/2), len(axis1)):\n",
    "            #Angles\n",
    "            sinT_i = data[m][c]*np.sin(np.radians(axis1[c]))\n",
    "            sinT_sum_2 = sinT_sum_2 + sinT_i\n",
    "            \n",
    "            cosT_i = data[m][c]*np.cos(np.radians(axis1[c]))\n",
    "            cosT_sum_2 = cosT_sum_2 + cosT_i\n",
    "            \n",
    "    \n",
    "        theta_net_1 = np.degrees(np.arctan(sinT_sum_1/cosT_sum_1))\n",
    "        theta_net_2 = 180+np.degrees(np.arctan(sinT_sum_2/cosT_sum_2))\n",
    "        ax[1,m].axvline(theta_net_1,c='k', lw=6, ls = ':')\n",
    "        ax[1,m].text(theta_net_1 - 18, np.max(smooth_y[20:])*1.1, r'$\\theta_{ns}$', size=24)\n",
    "        ax[1,m].axvline(theta_net_2,c='k', lw=6,  ls = ':', label = r'$\\theta_{n}$')\n",
    "        ax[1,m].text(theta_net_2 + 6 ,  np.max(smooth_y[20:])*1.1, r'$\\theta_{na}$', size=24)\n",
    "        print('Synthetic Net Theta = '+str(theta_net_1)+', Antithetic Net Theta = '+str(theta_net_2))\n",
    "      \n",
    "        #measure of symmetry:\n",
    "        #print('Theta_s - mode = '+str(theta_net_1-modes[2]))\n",
    "        #print('Theta_a - mode = '+str(theta_net_2-modes[2]))\n",
    "        Tn_syn = np.abs(theta_net_1-ims) # skewness of theta net synthetic\n",
    "        Tn_ant = np.abs(theta_net_2-ims) # skewness of theta net antithetic\n",
    "        num = Tn_syn - Tn_ant\n",
    "        deno = Tn_syn + Tn_ant\n",
    "        print('Asymmetry = '+str(num/deno))\n",
    "\n",
    "    ###LEGEND\n",
    "    ax[1,1].legend(loc=\"lower left\", bbox_to_anchor = (-0.9, -0.55), ncol=5)\n",
    "   \n",
    "    ###LABELS SUBPLOTS and GRID and SCIENTIFIC NOTATION\n",
    "    for n, a in enumerate(ax.flat):\n",
    "        a.text(-0.08, 1.1, string.ascii_lowercase[n]+\")\", transform = a.transAxes, size=22, weight = 'bold')\n",
    "        a.grid()\n",
    "        a.ticklabel_format(style='sci', axis = 'y', scilimits = (0,0))\n",
    "        a.set_xlabel(r'Orientation, $\\Theta_i (^o)$')\n",
    "    ###TITLES \n",
    "    ax[0,0].set_title('Shear Band')\n",
    "    ax[0,1].set_title('Whole Image')\n",
    "    ax[0,2].set_title('Outside Shear Band')\n",
    "    \n",
    "    #LABELS\n",
    "    ax[0,0].set_ylabel(r'$\\frac{F(\\Theta_{i})}{min(F(\\Theta_{0}))}$', fontsize=35)\n",
    "    ax[1,0].set_ylabel(r'$\\sum F(\\Theta_{i})$')\n",
    "    \n",
    "     \n",
    "   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data Residual Thresholding\n",
    "path_or_G = 'Residual_Thresholding_Fiji_output'\n",
    "nameR_or_G = '-nt_s2_roi.csv'\n",
    "nameW_or_G = '-nt_s2.csv'\n",
    "\n",
    "# data Skeletonisation\n",
    "path_or_S = 'Skeletonisation_Fiji_output'\n",
    "nameR_or_S = '-s1_lukeout_roi.csv'\n",
    "nameW_or_S = '-s1_lukeout.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Plotting Residual Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(22,9))\n",
    "plot_orientations(path_or_G, nameR_or_G, nameW_or_G, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Plotting Skeletonisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(22,9))\n",
    "plot_orientations(path_or_S, nameR_or_S, nameW_or_S, 5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
